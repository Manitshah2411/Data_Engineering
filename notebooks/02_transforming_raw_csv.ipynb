{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3781e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_cust = pd.read_csv('../data/raw/csv/customers.csv')\n",
    "df_pro = pd.read_csv('../data/raw/csv/products.csv')\n",
    "df_ord = pd.read_csv('../data/raw/csv/orders.csv')\n",
    "df_ordit = pd.read_csv('../data/raw/csv/order_items.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fa7aeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_purchase_timestamp         datetime64[ns]\n",
      "order_approved_at                datetime64[ns]\n",
      "order_delivered_carrier_date     datetime64[ns]\n",
      "order_delivered_customer_date    datetime64[ns]\n",
      "order_estimated_delivery_date    datetime64[ns]\n",
      "dtype: object\n",
      "order_purchase_timestamp            0\n",
      "order_approved_at                 160\n",
      "order_delivered_carrier_date     1783\n",
      "order_delivered_customer_date    2965\n",
      "order_estimated_delivery_date       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# converting the datetime columns from string to datetime\n",
    "date_cols = [\n",
    "    'order_purchase_timestamp',\n",
    "    'order_approved_at',\n",
    "    'order_delivered_carrier_date',\n",
    "    'order_delivered_customer_date',\n",
    "    'order_estimated_delivery_date'\n",
    "]\n",
    "\n",
    "for col in date_cols:\n",
    "    df_ord[col] = pd.to_datetime(df_ord[col], errors='coerce') # the columns are passed as a list and iterated to convert into datetime\n",
    "print(df_ord[date_cols].dtypes) \n",
    "print(df_ord[date_cols].isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1dfcd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "order_approved",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "b9bac6cd-b414-4a8c-8e69-d68288ee6d0c",
       "rows": [
        [
         "True",
         "99281"
        ],
        [
         "False",
         "160"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "order_approved\n",
       "True     99281\n",
       "False      160\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding a new column delayed_days, which means delivery_date - estimated_delivery_date\n",
    "\n",
    "df_ord['delayed_days'] = (df_ord['order_delivered_customer_date'] - df_ord['order_estimated_delivery_date']).dt.days\n",
    "df_ord['delayed_days'].head(10)\n",
    "\n",
    "\n",
    "# cleaning the orders table\n",
    "\n",
    "# order_approved_at means the order was cancelled\n",
    "# order_delivered_carrier_date isnull() means the order never shipped\n",
    "# order_delivered_customer_date isnull() means the order is never delivered\n",
    "\n",
    "# adding a new boolean column if the dilverey date is not null than true else False\n",
    "df_ord['order_completed'] = df_ord['order_delivered_customer_date'].notna()\n",
    "df_ord['order_completed'].value_counts()\n",
    "\n",
    "# adding a new boolean column for the carrier date for the same\n",
    "df_ord['order_shipped'] = df_ord['order_delivered_carrier_date'].notna()\n",
    "df_ord['order_shipped'].value_counts()\n",
    "\n",
    "# adding a new boolean column for the order approved for the same\n",
    "df_ord['order_approved'] = df_ord['order_approved_at'].notna()\n",
    "df_ord['order_approved'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bea87c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, [])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the integrity of the tables\n",
    "# validating FKs and finding orphans\n",
    "\n",
    "# finding orphan orders(Orders which does not have any customers)\n",
    "order_missing_customers = set(df_ord['customer_id']).difference(set(df_cust['customer_id']))\n",
    "len(order_missing_customers), list(order_missing_customers)[:10]\n",
    "\n",
    "# finding orphan order_items without order_id\n",
    "items_missing_orders = set(df_ordit['order_id']).difference(set(df_ord['order_id']))\n",
    "len(items_missing_orders), list(items_missing_orders)[:10]\n",
    "\n",
    "# finding oprhan order_items without products\n",
    "items_missing_products = set(df_ordit['product_id']).difference(set(df_pro['product_id']))\n",
    "len(items_missing_products), list(items_missing_products)[:10]\n",
    "\n",
    "# explaination : the columns are converted into set which means it contains only distinct values\n",
    "#                after that .difference() is like customers which are present in orders table but not in the customers table\n",
    "#                here the sequence matters, what you write before the difference and after it\n",
    "#                after the len() function is used to check is there is any missing values, if yes than extra steps are needed\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "607b905b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making order_items table ready for calculations\n",
    "\n",
    "df_ordit['price'] = pd.to_numeric(df_ordit['price'], errors='coerce') # here as the price is already in float64 this will make no \n",
    "# difference but in maximum cases it is needed to be checked in real world data\n",
    "\n",
    "\n",
    "df_ordit['quantity'] = 1\n",
    "\n",
    "# calc sales\n",
    "df_ordit['sales'] = df_ordit['price'] * df_ordit['quantity']\n",
    "\n",
    "df_ordit[['price','quantity','sales']].describe() # just some quick maths\n",
    "df_ordit['price'].isna().sum() # to check nulls in the price column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71e82a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 15 columns):\n",
      " #   Column                         Non-Null Count  Dtype         \n",
      "---  ------                         --------------  -----         \n",
      " 0   order_id                       99441 non-null  object        \n",
      " 1   customer_id                    99441 non-null  object        \n",
      " 2   order_status                   99441 non-null  object        \n",
      " 3   order_purchase_timestamp       99441 non-null  datetime64[ns]\n",
      " 4   order_approved_at              99281 non-null  datetime64[ns]\n",
      " 5   order_delivered_carrier_date   97658 non-null  datetime64[ns]\n",
      " 6   order_delivered_customer_date  96476 non-null  datetime64[ns]\n",
      " 7   order_estimated_delivery_date  99441 non-null  datetime64[ns]\n",
      " 8   delayed_days                   96476 non-null  float64       \n",
      " 9   order_completed                99441 non-null  bool          \n",
      " 10  order_shipped                  99441 non-null  bool          \n",
      " 11  order_approved                 99441 non-null  bool          \n",
      " 12  order_total                    99441 non-null  float64       \n",
      " 13  total_freight                  99441 non-null  float64       \n",
      " 14  num_items                      99441 non-null  float64       \n",
      "dtypes: bool(3), datetime64[ns](5), float64(4), object(3)\n",
      "memory usage: 9.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# calculating aggregations for the orders table \n",
    "\n",
    "orders_agg = df_ordit.groupby('order_id').agg(\n",
    "    order_total = ('sales','sum'), # it is a new column which sums the sales for the same order_id\n",
    "    total_freight = ('freight_value','sum'), # same as above for the freight\n",
    "    num_items = ('order_item_id','nunique')\n",
    ").reset_index() # as the groupby() coverts the targeted column into index so reset_index() converts it back to the column\n",
    "\n",
    "# df_ord = df_ord.merge(orders_agg, on='order_id', how='left')\n",
    "\n",
    "# filling all the missing values with zero for better calculations\n",
    "df_ord['order_total'] = df_ord['order_total'].fillna(0)\n",
    "df_ord['total_freight'] = df_ord['total_freight'].fillna(0)\n",
    "df_ord['num_items'] = df_ord['num_items'].fillna(0)\n",
    "\n",
    "# df_ord = df_ord.drop(columns=[\n",
    "#     'order_total_x', 'total_freight_x', 'num_items_x',\n",
    "#     'order_total_y', 'total_freight_y', 'num_items_y'\n",
    "# ])\n",
    "\n",
    "df_ord.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6a5e0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "customer_unique_id",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "99de12ae-85c5-414e-b59f-f6d73385a72f",
       "rows": [
        [
         "0",
         "7c396fd4830fd04220f754e42b4e5bff"
        ],
        [
         "1",
         "af07308b275d755c9edb36a90c618231"
        ],
        [
         "2",
         "3a653a41f6f9fc3d2a113cf8398680e8"
        ],
        [
         "3",
         "7c142cf63193a1473d2e66489a9ae977"
        ],
        [
         "4",
         "72632f0f9dd73dfee390c9b22eb56dd6"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/plain": [
       "0    7c396fd4830fd04220f754e42b4e5bff\n",
       "1    af07308b275d755c9edb36a90c618231\n",
       "2    3a653a41f6f9fc3d2a113cf8398680e8\n",
       "3    7c142cf63193a1473d2e66489a9ae977\n",
       "4    72632f0f9dd73dfee390c9b22eb56dd6\n",
       "Name: customer_unique_id, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating aggregations for customers table\n",
    "\n",
    "id_map = df_cust.set_index('customer_id')['customer_unique_id'].to_dict() # it creates a dictionary where the key is the customer_id and\n",
    "# value is the customer_unique_id\n",
    "\n",
    "df_ord['customer_unique_id'] = df_ord['customer_id'].map(id_map) # the id_map contains the id and unique_id, the customer_id of \n",
    "# orders table is matched with the id of the customers table and the unique id for that customer will be stored as the unique_id in \n",
    "# the orders table. \n",
    "\n",
    "df_ord['customer_unique_id'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a506525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregating according to the timeline of the orders table for the customers\n",
    "\n",
    "cutoff = df_ord['order_purchase_timestamp'].max() - pd.Timedelta(days=365)\n",
    "\n",
    "cust_agg = df_ord.groupby('customer_unique_id').agg(\n",
    "    first_order_date = ('order_purchase_timestamp','min'),\n",
    "    last_order_date = ('order_purchase_timestamp','max'),\n",
    "    num_orders = ('order_id','nunique'),\n",
    "    total_revenue = ('order_total','sum')\n",
    ").reset_index()\n",
    "\n",
    "cust_agg['active'] =  cust_agg['last_order_date'] >= cutoff\n",
    "cust_agg['active'] = cust_agg['active'].fillna(False)\n",
    "\n",
    "# df_cust = df_cust.merge(\n",
    "#     cust_agg,\n",
    "#     on='customer_unique_id',\n",
    "#     how='left'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b1e3c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the NaN with zeros \n",
    "\n",
    "df_cust['num_orders'] = df_cust['num_orders'].fillna(0)\n",
    "df_cust['total_revenue'] = df_cust['total_revenue'].fillna(0)\n",
    "df_cust['active'] = df_cust['active'].fillna(False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
